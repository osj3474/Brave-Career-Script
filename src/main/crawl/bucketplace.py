import requests
from bs4 import BeautifulSoup as bs
import re

def findByUrl(url):
    r = requests.get(url)
    html_doc = r.content
    soup = bs(html_doc, 'html.parser')
    return soup

default_url = "https://www.bucketplace.co.kr"
dev_url = "https://www.bucketplace.co.kr/recruit/?team=dev"
soup = findByUrl(dev_url)

soup = soup.select_one("div.recruit-page__job-list__list__wrap") # /staticì— 'ê°œë°œ' ê³¼ ë‹¤ë¥¸ ì§ë¬´ ìˆì–´ì„œ ì´ë ‡ê²Œ 1ì°¨ë¡œ ê±°ë¦„.
html_lst = soup.find_all("a", {"class":"recruit-page__job-list__list__wrap__item"})
p = re.compile('href\=\"(.+)\/\"\>')    # href="(recruit_url)" ì„ ì–»ì–´ë‚´ëŠ” ê²ƒ


url_lst = list()   # ì±„ìš© í¬ì§€ì…˜ url
for html in html_lst:
    url = re.findall(p, str(html))
    url_lst.append(url[0])

# comany : 'ì˜¤ëŠ˜ì˜ ì§‘'
# potision : div
# period : 'ìˆ˜ì‹œ'
position_lst = list()
recruit_lst = list()
for u in url_lst:
    recruit_url = default_url + u
    recruit_lst.append(recruit_url)
    soup = findByUrl(recruit_url)
    position = soup.find_all("div", {"class":"position-content__head__name"})
    position = position[0].text
    position_lst.append(position)
    print(position)

length = len(position_lst)
with open('../../../test.md', 'r') as f:
    new_file = list()
    while True:
        line = f.readline()
        if not line: break
        if "# ğŸšŒ ì§„í–‰ ì¤‘ì¸ ê³µê³ " == line.strip():
            for i in range(length):
                line = line+("""
- __<a href="{}" target='_blank'>{}</a>__

  - í¬ì§€ì…˜ : {}

  - ê¸°ê°„ : ìˆ˜ì‹œ



""".format(recruit_lst[i], position_lst[i], position_lst[i]+" ì±„ìš©"))
        new_file.append(line)

with open('./now.md', 'w') as doc:
    doc.writelines(new_file)

# Tips) í•˜ìœ„ í´ë˜ìŠ¤ ì¡ì„ë•Œ
# html_lst = soup.select("div.recruit-page__job-list__list__wrap > a.recruit-page__job-list__list__wrap__item")